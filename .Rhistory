for(d in distances)
{
disp = matrix(d, height, width)
center_ind = sample(1:nrow(all_center), s_size)
for(c in center_ind)
{
tab = dispersal(all_center[c, 1], all_center[c, 2], fecundity)
center_loss[which(center_ind == c), d] = off_same(tab)
}
edge_ind = sample(1:nrow(all_edge), s_size)
for(e in edge_ind)
{
tab = dispersal(all_edge[e, 1], all_edge[e, 2], fecundity)
edge_loss[which(edge_ind == e), d] = off_same(tab)
}
}
table(edge_loss)
table(center_loss)
fecundity
edge_loss
distances = 1:15
s_size = 7e4
# we are also interested in the impact of fecundity
fecundity = 10
# establishing dispersal distance for each thing
disp = matrix(2, 250, 1500)
# Establishing an empty table for edge and center to put stuff
center_loss = matrix(rep(NA, (s_size * length(distances))), nrow = s_size,
ncol = length(distances))
edge_loss = matrix(rep(NA, (s_size * length(distances))), nrow = s_size,
ncol = length(distances))
# We will look at a variety of dispersal distances. Each column will hold all the
# individual measures of loss from the different dispersal distances.
for(d in distances)
{
disp = matrix(d, height, width)
center_ind = sample(1:nrow(all_center), s_size)
for(c in center_ind)
{
tab = dispersal(all_center[c, 1], all_center[c, 2], fecundity)
center_loss[which(center_ind == c), d] = off_same(tab)
if(off_same(tab) > 10) {print(tab)}
}
edge_ind = sample(1:nrow(all_edge), s_size)
for(e in edge_ind)
{
tab = dispersal(all_edge[e, 1], all_edge[e, 2], fecundity)
edge_loss[which(edge_ind == e), d] = off_same(tab)
if(off_same(tab) > 10) {print(tab)}
}
}
?matrix
matrix(c(132, 213, 132, 217, 131, 215, 129, 217, 131, 215, 131, 215, 130, 218, 131, 215, 131, 215, 131, 215), nrow = 2, ncol = 10)
test = matrix(c(132, 213, 132, 217, 131, 215, 129, 217, 131, 215, 131, 215, 130, 218, 131, 215, 131, 215, 131, 215), nrow = 2, ncol = 10)
off_same(test)
l_pairs = 0
row1 = unique(test[1, ])
row1
testers = test[2, which(d_tab[1, ] == u)]
testers
testers = test[2, which(d_tab[1, ] == 132)]
testers
testers = test[2, which(test[1, ] == 132)]
testers
testers = test[2, which(test[1, ] == 131)]
test
testers
u_testers
testers = c(215, 215, 126, 215, 217)
u_testers = unique(testers)
u_testers
which(testers == 215)
off_same = function(d_tab)
{
l_pairs = 0
u_row1 = unique(d_tab[1,])
for(u in u_row1)
{
testers = d_tab[2, which(d_tab[1, ] == u)]
u_testers = unique(testers)
for(u in u_testers) {l_pairs = l_pairs + (length(which(testers == u)) - 1)}
}
return(l_pairs)
}
test
off_same(test)
distances = 1:15
s_size = 7e4
# we are also interested in the impact of fecundity
fecundity = 10
# establishing dispersal distance for each thing
disp = matrix(2, 250, 1500)
# Establishing an empty table for edge and center to put stuff
center_loss = matrix(rep(NA, (s_size * length(distances))), nrow = s_size,
ncol = length(distances))
edge_loss = matrix(rep(NA, (s_size * length(distances))), nrow = s_size,
ncol = length(distances))
# We will look at a variety of dispersal distances. Each column will hold all the
# individual measures of loss from the different dispersal distances.
for(d in distances)
{
disp = matrix(d, height, width)
center_ind = sample(1:nrow(all_center), s_size)
for(c in center_ind)
{
tab = dispersal(all_center[c, 1], all_center[c, 2], fecundity)
center_loss[which(center_ind == c), d] = off_same(tab)
}
edge_ind = sample(1:nrow(all_edge), s_size)
for(e in edge_ind)
{
tab = dispersal(all_edge[e, 1], all_edge[e, 2], fecundity)
edge_loss[which(edge_ind == e), d] = off_same(tab)
}
}
table(edge_loss)
table(center_loss)
boxplot(edge_loss)
table(edge_loss[, 1])
mean(edge_loss[, 1])
boxplot(edge_loss, xlab = "Dispersal distance", ylab = "Expected # offspring lost to repeat", main = "Edge spots")
boxplot(edge_loss, xlab = "Dispersal distance", ylab = "Expected # offspring lost to repeat", main = "Edge spots, fec = 10")
colMeans(edge_loss)
edge_fec_10 = colMeans(edge_loss)
plot(1:15, edge_fec_10, type = "l")
boxplot(center_loss, xlab = "Dispersal distance", ylab = "Expected # offspring lost to repeat", main = "Central spots, fec = 10")
center_fec_10 = colMeans(center_loss)
center_fec_10
distances = 1:15
s_size = 7e4
# we are also interested in the impact of fecundity
fecundity = 3
# establishing dispersal distance for each thing
disp = matrix(2, 250, 1500)
# Establishing an empty table for edge and center to put stuff
center_loss = matrix(rep(NA, (s_size * length(distances))), nrow = s_size,
ncol = length(distances))
edge_loss = matrix(rep(NA, (s_size * length(distances))), nrow = s_size,
ncol = length(distances))
# We will look at a variety of dispersal distances. Each column will hold all the
# individual measures of loss from the different dispersal distances.
for(d in distances)
{
disp = matrix(d, height, width)
center_ind = sample(1:nrow(all_center), s_size)
for(c in center_ind)
{
tab = dispersal(all_center[c, 1], all_center[c, 2], fecundity)
center_loss[which(center_ind == c), d] = off_same(tab)
}
edge_ind = sample(1:nrow(all_edge), s_size)
for(e in edge_ind)
{
tab = dispersal(all_edge[e, 1], all_edge[e, 2], fecundity)
edge_loss[which(edge_ind == e), d] = off_same(tab)
}
}
boxplot(center_loss, xlab = "Dispersal distance", ylab = "Expected # offspring lost to repeat", main = "Central spots, fec = 3")
boxplot(edge_loss, xlab = "Dispersal distance", ylab = "Expected # offspring lost to repeat", main = "Edge spots, fec = 3")
center_fec_3 = colMeans(center_loss)
edge_fec_3 = colMeans(edge_loss)
center_fec_3
edge_fec_3
center_fec_10
edge_fec_10
plot(1:15, seq(from = 0, to = 2.75, length.out = length(1:15)), type = "n")
points(1:15, edge_fec_10, type = "l", lwd = 2)
plot(1:15, seq(from = 0, to = 2.75, length.out = length(1:15)), type = "n", log = "y", main = "Expected offspring loss", xlab = "Dispersal", ylab = "Expected loss")
points(1:15, edge_fec_10, type = "l", lwd = 2)
points(1:15, edge_fec_10, type = "l", lwd = 2, log = "y")
plot(1:15, seq(from = 0, to = 2.75, length.out = length(1:15)), type = "n", log = "y", main = "Expected offspring loss", xlab = "Dispersal", ylab = "Expected loss")
plot(1:15, seq(from = 0, to = 2.75, length.out = length(1:15)), type = "n", main = "Expected offspring loss", xlab = "Dispersal", ylab = "Expected loss")
points(1:15, edge_fec_10, type = "l", lwd = 2)
points(1:15, center_fec_10, type = "l", lwd = 2)
points(1:15, center_fec_3, type = "l", lwd = 2)
points(1:15, edge_fec_3, type = "l", lwd = 2)
library(stringr)
install.packages('stringr')
plate = read.csv(file = '/Users/caitlinmiller/Downloads/example curves.xlsx')
plate
plate = read.csv(file = '/Users/caitlinmiller/Downloads/example curves.csv')
plate
layout_s = which(plate == 'Layout', arr.ind = TRUE)[1] + 2
c_start = which(plate[layout_s, ] == 1)
# output of layout wells
layout_wells = plate[(layout_s + 1):(layout_s + 8), c_start:(c_start + 11)]
non_empty = which(layout_wells != '', arr.ind = TRUE)
non_empty
layout_wells
time_loc = which(plate == 'Time', arr.ind = TRUE)[2,]
col_start = time_loc[2] + 2
col_end = col_start + (nrow(non_empty) - 1)
row_start = time_loc[1] + 1
pars = which(plate == 'Start Kinetic', arr.ind = TRUE)
# this is the string that we will need to search to find the number of reads
platestring = plate[pars[1], pars[2] + 1]
time_loc
col_Start
col_start
row_start
plate[41, 4]
plate
pars
platestring
just_reads
just_reads = str_extract(platestring, '((\\d\\d )|(\\d\\d\\d ))Reads')
library(stringr)
just_reads = str_extract(platestring, '((\\d\\d )|(\\d\\d\\d ))Reads')
numbers = str_extract_all(just_reads, '[^ Reads]')
# This should provide the number of reads in a usable format.
num_reads = as.numeric(paste(unlist(numbers), collapse = ""))
just_redas
just_reads
num_reads
just_int = str_extract(platestring, 'Interval (\\d:\\d\\d:\\d\\d)')
hrs = str
just_int
hrs = str(just_int, '\\d:\\d\\d:\\d\\d')
hrs = str_extract(just_int, '\\d:\\d\\d:\\d\\d')
hrs
str_split(hrs, :)
?str_split
str_split(hrs, ':')
times = str_split(hrs, ':')
times
times[1]
times[[1]][1]
times[[1]][2]
times[[1]][3]
as.numeric(times[[1]][1])
int_time = int_time + as.numeric(times[[1]][2])/60
int_time = as.numeric(times[[1]][1])
int_time = int_time + as.numeric(times[[1]][2])/60
int_time
times = str_split(hrs, ':')
int_time = as.numeric(times[[1]][1])
int_time = int_time + as.numeric(times[[1]][2])/60
int_time = int_time + as.numeric(times[[1]][3])/360
int_time
row_end = row_start + (num_reads - 1)
row_start
row_end
41+73
num_reads
plate
plate[40:115, 4]
40 + 66
plate[41:115, 4]
41+66
row_end
66-1
plate[113, 4]
int_time
t = 4
1 + 4
plate
plate[41, 4]
plate[45, 4]
log(.094) - log(.091)
(log(.094) - log(.091))/1
time_size(4)
time_size = function(t)
{
return(t * int_time)
}
time_size(4)
times = seq(from = 14, to = (14 * 73), by = 15)
times
plot(times, plate[41, 4])
length(plate[41, 4])
length(plate[41:113, 4])
length(times)
times = seq(from = 14, to = (15 * 73), by = 15)
times
length(times)
plot(times, plate[41:113, 4])
test = bac_gr(plate[41:113], 4)
bac_gr = function(ods, t)
{
for(od_ind in 1:(length(ods) - t))
{
(log(ods[od_ind + t]) - log(ods[od_ind]))/(time_size(t))
}
}
test = bac_gr(plate[41:113], 4)
test = bac_gr(plate[41:113, 4], 4)
test = bac_gr(as.numeric(plate[41:113, 4]), 4)
test
as.numeric(plate[41:113, 4])
bac_gr = function(ods, t)
{
for(od_ind in 1:(length(ods) - t))
{
growths = c(growths, (log(ods[od_ind + t]) - log(ods[od_ind]))/(time_size(t)))
}
return(growths)
}
bac_gr(as.numeric(plate[41:113, 4]), 4)
bac_gr = function(ods, t)
{
growths = NULL
for(od_ind in 1:(length(ods) - t))
{
growths = c(growths, (log(ods[od_ind + t]) - log(ods[od_ind]))/(time_size(t)))
}
return(growths)
}
bac_gr(as.numeric(plate[41:113, 4]), 4)
test = bac_gr(as.numeric(plate[41:113, 4]), 4)
plot(times, test)
length(test)
plot(times[1:70], test)
length(1:69)
plot(times[1:69], test)
plot(times, as.numeric(plate[41:113, 4]), type = "l", lwd = 4, xlab = "Time in min", ylab = "OD")
test_hr = bac_gr(as.numeric(plate[41:113, 4]), 4)
test_.5hr = bac_gr(as.numeric(plate[41:113, 4]), 2)
test_2hr = bac_gr(as.numeric(plate[41:113, 4]), 8)
plot(times[1:69], test_hr, type = "l", lwd = 4, xlab = "Time", ylab = "Growth rate")
points(times[1:71], test_.5hr, type= "l", lwd = 4, col = "red")
points(times[1:65], test_2hr, type= "l", lwd = 4, col = "blue")
legend(760, .3, legend = c('.5 hr', '1 hr', '2 hr'), lwd = 4, col = c('red', 'black', 'blue'))
sample(1:360, 10)
sample(1:360, 10)
site.name = 'KonzaPrairie'
locale.name = 'gall'
data1 = read.csv("/Users/caitlinmiller/Desktop/Github/insect_apoc/CGP011.csv",as.is=T,check.names=F,header=T)
data1$Year = data1$RecYear
data1$Number = data1$GalledStems
u.years = sort(as.numeric(unique(data1$Year)))
out.slopes = data.frame('LTER.site'=NA,'Locale'=NA,'Species.code'=NA,'Year'=-999,'N.Obs'=-999,'Abundance'=-999)
cx = 1
for (y in 1:length(u.years)){
y.data = data1[which(data1$Year==u.years[y]),]
n.y1 = sum(y.data$SampledStems,na.rm=T)
out.slopes[cx,1] = site.name #LTER.site
out.slopes[cx,2] = locale.name #Locale
out.slopes[cx,3] = 'gall insects' #Species.code
out.slopes[cx,4] = u.years[y] #Year
out.slopes[cx,5] = n.y1 #Number of observations
out.slopes[cx,6] = sum(y.data$Number,na.rm=T) #abundance
cx = cx + 1
}
out.slopes
write.table(out.slopes,paste0('./summary_tables/arthropods/Species-level/',site.name,'_GallInsect_SpeciesSlopes.txt'),sep='\t',quote=F,row.names=F)
gall_out = out.slopes
site.name = 'KonzaPrairie'
locale.name = 'grasshopper'
data1 = read.csv("/Users/caitlinmiller/Desktop/Github/insect_apoc/CGR022.csv",as.is=T,check.names=F,header=T)
data1
data1 = data1[which(data1$Species!='unknown' & data1$Species!='unknown ' & data1$Species!=''),]
site.name = 'KonzaPrairie'
locale.name = 'grasshopper'
data1 = read.csv("/Users/caitlinmiller/Desktop/Github/insect_apoc/CGR022.csv",as.is=T,check.names=F,header=T)
data1$Species = data1$SPECIES
data1$Year = data1$RECYEAR
data1$Number = as.numeric(data1$TOTAL)
nrow(data1)
data1 = data1[which(data1$Species!='unknown' & data1$Species!='unknown ' & data1$Species!=''),]
nrow(data1)
u.years = sort(as.numeric(unique(data1$Year)))
u.years
u.species = unique(data1$Species)
u.species
konza.duplicates = read.csv('/Users/caitlinmiller/Downloads/External_Database_S3/taxa_keys/KonzaPrairie_grasshoppers_duplicatenames.csv',
as.is=T,check.names=F,header=F)
konza.duplicates
konza.duplicates[2, V1]
konza.duplicates[2, 1]
konza.duplicates[2, 2]
class(konza.duplicates[2, 2])
class(konza.duplicates[2, 1])
which(konza.duplicates[,1]==data1$Species[2])
konza.duplicates[56, ]
which(konza.duplicates[,1] == 'Melanoplus scudderi')
konza.duplicates[57, ]
which(konza.duplicates[,1] == 'huh')
konza.duplicates[which(konza.duplicates[,1] == 'huh'), 2]
?match
konza.duplicates
data1 = data1[which(data1$Species!='Unknown'),]
for (i in 1:nrow(data1)){
name.swap = konza.duplicates[which(konza.duplicates[,1]==data1$Species[i]),2]
if (length(name.swap)==0){
name.swap = konza.duplicates[match(data1$Species[i],konza.duplicates[,2]),2]
} else {
}
data1$Species[i] = name.swap
}
u.species
u.species1 = u.species
u.species = unique(data1$Species)
u.species1 == u.species
u.species
length(u.species1)
length(u.species)
out.diversity = data.frame('LTER.site'=NA,'Locale'=NA,'Year'=-999,'N.obs'=-999,'Total.abundance'=-999,'N.species'=-999,'Species.evenness'=-999,'Species.decay.rate'=-999,'Fishers.alpha'=-999,'Dominance'=-999)
out.diversity
lx = 1
u.years
u.years[1]
y = 1
y.data = data1[which(data1$Year==u.years[y]),]
data1[y.data, ]
y.data
table(y.data$Year)
paste(y.data$RECMONTH,y.data$RECDAY,y.data$REPSITE,sep='_')
unique(paste(y.data$RECMONTH,y.data$RECDAY,y.data$REPSITE,sep='_'))
y.data$Species
y.data$Number
y.data$Number[1:10]
y.data$Species[1:10]
small_sp = y.data$Species[1:10]
small_no = y.data$Number[1:10]
sp1 = small_sp
ab1 = small_no
unique(sp1)
usp = unique(sp1)
usp
array(usp)
class(usp)
class(array(usp))
?apply
array(usp)[1]
array(usp)[1, ]
function(x){sum(ab1[which(sp1==x)],na.rm=T)}
ab1
sp``
sp1
spc = apply(array(usp),1,function(x){sum(ab1[which(sp1==x)],na.rm=T)})
spc
rich = length(which(spc>0))
rich = length(which(spc>0))
spc
sum(spc)
spc/sum(spc)
spcp
.0594059 * log(.0594059)
0 * log(0)
.0001 * log(.0001)
.5 * log(.5)
.9 * log(.9)
.1 * log(.1)
.09482446 + .2302585
.5 * log(.5)
log(.1)
log(.9)
length(spcp)
spcp = spc / sum(spc,na.rm=T)
spcp
length(spcp)
log(7)
log(10)
log(5)
(.25 * log(.25)) * 4
1.386/(log(4))
(.5 * log(.5)) * 2
.69315/(log(2))
(.1 * log(.1)) * 10
2.3/(log(10))
?str
cats <- data.frame(coat = c('calico', 'black', 'tabby'), weight = c(2.1, 5.0, 3.2), likes_catnip = c(1, 0, 1))
cats
cats
age <- c(2, 3, 5)
age
cbind(cats, age)
age <- c(2, 3)
cbind(cats, age)
length(age)
age
nrow(cats)
age <- c(2, 3, 5)
cats <- cbind(cats, age)
cats
cats <- data.frame(coat = c('calico', 'black', 'tabby'), weight = c(2.1, 5.0, 3.2), likes_catnip = c(1, 0, 1))
cats
cats
age <- c(2, 3, 5)
cbind(cats, ages)
cbind(cats, age)
age <- c(2, 3)
cbind(cats, age)
length(age)
nrow(cats)
cats <- data.frame(coat = c('calico', 'black', 'tabby'), weight = c(2.1, 5.0, 3.2), likes_catnip = c(1, 0, 1))
cats
cats
age <- c(2, 3, 5)
age
cbind(cats, age)
age <- c(2, 3)
cbind(cats, age)
length(age)
nrow(cats)
getwd()
setwd('/Users/caitlinmiller/Desktop/Github/insect_apoc')
data1 = read.csv('PerSpecies_Abundance_LTER_annotated.csv',as.is=T,check.names=F,header=T)
u.species = unique(data1$Species.code)
no_species = length(u.species)
slopes = rep(NA, no_species)
max_abun = rep(NA, no_species)
start_abun = rep(NA, no_species)
for(spp in 1:no_species)
{
spp_i = which(data1$Species.code == u.species[spp])
slopes[spp] = as.numeric(lm(Abundance ~ Year, data = data1[spp_i, ])[[1]][2])
max_abun[spp] = max(data1$Abundance[spp_i])
# For start abundance, I will take an average of the first 5 measurements to account for the possibility
# that the first measurement is an outlier.
start_abun[spp] = mean(data1$Abundance[spp_i][1:5])
}
